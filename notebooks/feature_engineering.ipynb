{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/completed_orders.csv')\n",
    "delivery_requests = pd.read_csv('../data/drivers_location_during_request.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Trip ID   | Trip Origin                        | Trip Destination                | Trip Start Time     | Trip End Time       | day_of_week   | hour_of_day   | day_of_month   | month   | Trip Origin_latitude   | Trip Origin_longitude   | Trip Destination_latitude   | Trip Destination_longitude   | trip_duration   |\n",
      "|:----------|:-----------------------------------|:--------------------------------|:--------------------|:--------------------|:--------------|:--------------|:---------------|:--------|:-----------------------|:------------------------|:----------------------------|:-----------------------------|:----------------|\n",
      "| 391996    | 6.508813001668548,3.37740316890347 | 6.650969799999999,3.3450307     | 2021-07-01 07:28:04 | 2021-07-01 07:29:37 | Thursday      | 7             | 1              | July    | 6.50881                | 3.3774                  | 6.65097                     | 3.34503                      | 93              |\n",
      "| 391997    | 6.4316714,3.4555375                | 6.4280814653326,3.4721885847586 | 2021-07-01 06:38:04 | 2021-07-01 07:07:28 | Thursday      | 6             | 1              | July    | 6.43167                | 3.45554                 | 6.42808                     | 3.47219                      | 1764            |\n",
      "| 391998    | 6.631679399999999,3.3388976        | 6.508324099999999,3.3590397     | 2021-07-01 06:21:02 | 2021-07-01 07:02:23 | Thursday      | 6             | 1              | July    | 6.63168                | 3.3389                  | 6.50832                     | 3.35904                      | 2481            |\n",
      "| 391999    | 6.572757200000001,3.3677082        | 6.584881099999999,3.3614073     | 2021-07-01 07:16:07 | 2021-07-01 07:29:42 | Thursday      | 7             | 1              | July    | 6.57276                | 3.36771                 | 6.58488                     | 3.36141                      | 815             |\n",
      "| 392001    | 6.6010417,3.2766339                | 6.4501069,3.3916154             | 2021-07-01 09:30:59 | 2021-07-01 09:34:36 | Thursday      | 9             | 1              | July    | 6.60104                | 3.27663                 | 6.45011                     | 3.39162                      | 217             |\n"
     ]
    }
   ],
   "source": [
    "## Feature Engineering\n",
    "# Extract date components from timestamps\n",
    "\n",
    "# Convert `Trip Start Time` and `Trip End Time` to datetime\n",
    "df['Trip Start Time'] = pd.to_datetime(df['Trip Start Time'])\n",
    "df['Trip End Time'] = pd.to_datetime(df['Trip End Time'])\n",
    "\n",
    "# Impute missing values in `Trip Start Time` with the median\n",
    "median_start_time = df['Trip Start Time'].median()\n",
    "df['Trip Start Time'] = df['Trip Start Time'].fillna(median_start_time)\n",
    "\n",
    "# Extract `day_of_week`, `hour_of_day`, `day_of_month`, and `month` from `Trip Start Time`\n",
    "df['day_of_week'] = df['Trip Start Time'].dt.day_name()\n",
    "df['hour_of_day'] = df['Trip Start Time'].dt.hour\n",
    "df['day_of_month'] = df['Trip Start Time'].dt.day\n",
    "df['month'] = df['Trip Start Time'].dt.month_name()\n",
    "\n",
    "# Extract `latitude` and `longitude` from `Trip Origin` and `Trip Destination`\n",
    "for col in ['Trip Origin', 'Trip Destination']:\n",
    "    df[[f'{col}_latitude', f'{col}_longitude']] = df[col].str.split(',', expand=True).astype(float)\n",
    "\n",
    "# Calculate `trip_duration` in seconds\n",
    "df['trip_duration'] = (df['Trip End Time'] - df['Trip Start Time']).dt.total_seconds()\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip ID</th>\n",
       "      <th>Trip Origin</th>\n",
       "      <th>Trip Destination</th>\n",
       "      <th>Trip Start Time</th>\n",
       "      <th>Trip End Time</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "      <th>Trip Origin_latitude</th>\n",
       "      <th>Trip Origin_longitude</th>\n",
       "      <th>Trip Destination_latitude</th>\n",
       "      <th>Trip Destination_longitude</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536015</th>\n",
       "      <td>1637696</td>\n",
       "      <td>6.448218499999999,3.4772075</td>\n",
       "      <td>6.437787399999999,3.481670199999999</td>\n",
       "      <td>2021-12-30 20:35:06</td>\n",
       "      <td>2021-12-30 21:02:59</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>December</td>\n",
       "      <td>6.448218</td>\n",
       "      <td>3.477208</td>\n",
       "      <td>6.437787</td>\n",
       "      <td>3.481670</td>\n",
       "      <td>1673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536016</th>\n",
       "      <td>1637702</td>\n",
       "      <td>6.442320899999999,3.4736868</td>\n",
       "      <td>6.436589333407897,3.5559738188407835</td>\n",
       "      <td>2021-12-30 20:48:13</td>\n",
       "      <td>2021-12-30 21:43:49</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>December</td>\n",
       "      <td>6.442321</td>\n",
       "      <td>3.473687</td>\n",
       "      <td>6.436589</td>\n",
       "      <td>3.555974</td>\n",
       "      <td>3336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536017</th>\n",
       "      <td>1637704</td>\n",
       "      <td>6.4281982,3.492248</td>\n",
       "      <td>6.448088500000001,3.4775747</td>\n",
       "      <td>2021-12-30 20:51:45</td>\n",
       "      <td>2021-12-30 21:41:32</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>December</td>\n",
       "      <td>6.428198</td>\n",
       "      <td>3.492248</td>\n",
       "      <td>6.448089</td>\n",
       "      <td>3.477575</td>\n",
       "      <td>2987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536018</th>\n",
       "      <td>1637705</td>\n",
       "      <td>6.5869296,3.3632966</td>\n",
       "      <td>6.637906899999999,3.3339515</td>\n",
       "      <td>2021-12-30 20:48:50</td>\n",
       "      <td>2021-12-30 21:08:28</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>December</td>\n",
       "      <td>6.586930</td>\n",
       "      <td>3.363297</td>\n",
       "      <td>6.637907</td>\n",
       "      <td>3.333951</td>\n",
       "      <td>1178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536019</th>\n",
       "      <td>1637709</td>\n",
       "      <td>6.647209999999999,3.4851489</td>\n",
       "      <td>6.454915198823159,3.555839938365194</td>\n",
       "      <td>2021-12-30 20:55:38</td>\n",
       "      <td>2021-12-30 22:25:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>December</td>\n",
       "      <td>6.647210</td>\n",
       "      <td>3.485149</td>\n",
       "      <td>6.454915</td>\n",
       "      <td>3.555840</td>\n",
       "      <td>5362.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Trip ID                  Trip Origin  \\\n",
       "536015  1637696  6.448218499999999,3.4772075   \n",
       "536016  1637702  6.442320899999999,3.4736868   \n",
       "536017  1637704           6.4281982,3.492248   \n",
       "536018  1637705          6.5869296,3.3632966   \n",
       "536019  1637709  6.647209999999999,3.4851489   \n",
       "\n",
       "                            Trip Destination     Trip Start Time  \\\n",
       "536015   6.437787399999999,3.481670199999999 2021-12-30 20:35:06   \n",
       "536016  6.436589333407897,3.5559738188407835 2021-12-30 20:48:13   \n",
       "536017           6.448088500000001,3.4775747 2021-12-30 20:51:45   \n",
       "536018           6.637906899999999,3.3339515 2021-12-30 20:48:50   \n",
       "536019   6.454915198823159,3.555839938365194 2021-12-30 20:55:38   \n",
       "\n",
       "             Trip End Time day_of_week  hour_of_day  day_of_month     month  \\\n",
       "536015 2021-12-30 21:02:59    Thursday           20            30  December   \n",
       "536016 2021-12-30 21:43:49    Thursday           20            30  December   \n",
       "536017 2021-12-30 21:41:32    Thursday           20            30  December   \n",
       "536018 2021-12-30 21:08:28    Thursday           20            30  December   \n",
       "536019 2021-12-30 22:25:00    Thursday           20            30  December   \n",
       "\n",
       "        Trip Origin_latitude  Trip Origin_longitude  \\\n",
       "536015              6.448218               3.477208   \n",
       "536016              6.442321               3.473687   \n",
       "536017              6.428198               3.492248   \n",
       "536018              6.586930               3.363297   \n",
       "536019              6.647210               3.485149   \n",
       "\n",
       "        Trip Destination_latitude  Trip Destination_longitude  trip_duration  \n",
       "536015                   6.437787                    3.481670         1673.0  \n",
       "536016                   6.436589                    3.555974         3336.0  \n",
       "536017                   6.448089                    3.477575         2987.0  \n",
       "536018                   6.637907                    3.333951         1178.0  \n",
       "536019                   6.454915                    3.555840         5362.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Trip Duration Summary Statistics:\n",
      "|       | trip_duration   |\n",
      "|:------|:----------------|\n",
      "| count | 534324          |\n",
      "| mean  | 4555.05         |\n",
      "| std   | 11517.9         |\n",
      "| min   | 1               |\n",
      "| 25%   | 2021            |\n",
      "| 50%   | 3177            |\n",
      "| 75%   | 4807            |\n",
      "| max   | 794381          |\n"
     ]
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Filter out negative trip durations\n",
    "df_filtered = df[df['trip_duration'] > 0].copy()\n",
    "\n",
    "# Filter out trip durations exceeding three standard deviations from the mean\n",
    "mean_trip_duration = df_filtered['trip_duration'].mean()\n",
    "std_trip_duration = df_filtered['trip_duration'].std()\n",
    "df_filtered = df_filtered[df_filtered['trip_duration'] <= mean_trip_duration + 3 * std_trip_duration]\n",
    "\n",
    "# Recalculate and print summary statistics for `trip_duration`\n",
    "print(\"Filtered Trip Duration Summary Statistics:\")\n",
    "print(df_filtered['trip_duration'].describe().to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "# Scatter plot of Trip Origins colored by hour_of_day\n",
    "chart1 = alt.Chart(df_filtered).mark_circle(size=60).encode(\n",
    "    x=alt.X('Trip Origin_longitude:Q', title='Longitude'),\n",
    "    y=alt.Y('Trip Origin_latitude:Q', title='Latitude'),\n",
    "    color=alt.Color('hour_of_day:O', scale=alt.Scale(scheme='category20'), legend=alt.Legend(title='Hour of Day')),\n",
    "    tooltip=['Trip Origin_latitude:Q', 'Trip Origin_longitude:Q', 'hour_of_day:O']\n",
    ").properties(\n",
    "    title='Trip Origins Colored by Hour of Day'\n",
    ").interactive()\n",
    "\n",
    "chart1.save('trip_origins_colored_by_hour.json')\n",
    "\n",
    "# Scatter plot of Trip Destinations colored by hour_of_day\n",
    "chart2 = alt.Chart(df_filtered).mark_circle(size=60).encode(\n",
    "    x=alt.X('Trip Destination_longitude:Q', title='Longitude'),\n",
    "    y=alt.Y('Trip Destination_latitude:Q', title='Latitude'),\n",
    "    color=alt.Color('hour_of_day:O', scale=alt.Scale(scheme='category20'), legend=alt.Legend(title='Hour of Day')),\n",
    "    tooltip=['Trip Destination_latitude:Q', 'Trip Destination_longitude:Q', 'hour_of_day:O']\n",
    ").properties(\n",
    "    title='Trip Destinations Colored by Hour of Day'\n",
    ").interactive()\n",
    "\n",
    "chart2.save('trip_destinations_colored_by_hour.json')\n",
    "\n",
    "# 2D histogram of Trip Origins\n",
    "chart3 = alt.Chart(df_filtered).mark_rect().encode(\n",
    "    x=alt.X('Trip Origin_longitude:Q', bin=True, title='Longitude'),\n",
    "    y=alt.Y('Trip Origin_latitude:Q', bin=True, title='Latitude'),\n",
    "    color=alt.Color('count()', title='Density'),\n",
    "    tooltip=[alt.Tooltip('Trip Origin_longitude:Q', bin=True, title='Longitude'), alt.Tooltip('Trip Origin_latitude:Q', bin=True, title='Latitude'), 'count()']\n",
    ").properties(\n",
    "    title='Density of Trip Origins'\n",
    ").interactive()\n",
    "\n",
    "chart3.save('trip_origins_density.json')\n",
    "\n",
    "# 2D histogram of Trip Destinations\n",
    "chart4 = alt.Chart(df_filtered).mark_rect().encode(\n",
    "    x=alt.X('Trip Destination_longitude:Q', bin=True, title='Longitude'),\n",
    "    y=alt.Y('Trip Destination_latitude:Q', bin=True, title='Latitude'),\n",
    "    color=alt.Color('count()', title='Density'),\n",
    "    tooltip=[alt.Tooltip('Trip Destination_longitude:Q', bin=True, title='Longitude'), alt.Tooltip('Trip Destination_latitude:Q', bin=True, title='Latitude'), 'count()']\n",
    ").properties(\n",
    "    title='Density of Trip Destinations'\n",
    ").interactive()\n",
    "\n",
    "chart4.save('trip_destinations_density.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRowsError",
     "evalue": "The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxRowsError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maltair_saver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save the chart as a PNG image\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchart1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchart1.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair_saver/_core.py:161\u001b[0m, in \u001b[0;36msave\u001b[0;34m(chart, fp, fmt, mode, embed_options, method, suppress_data_warning, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m alt\u001b[38;5;241m.\u001b[39mdata_transformers\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;129;01min\u001b[39;00m [alt\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto_json, alt\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto_csv]:\n\u001b[1;32m    156\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave() may not function properly with the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malt\u001b[38;5;241m.\u001b[39mdata_transformers\u001b[38;5;241m.\u001b[39mactive\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata transformer: use alt.data_transformers.enable(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m). To \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuppress this warning, pass suppress_data_warning=True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mchart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     mode \u001b[38;5;241m=\u001b[39m infer_mode_from_spec(spec)\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/vegalite/v5/api.py:2975\u001b[0m, in \u001b[0;36mChart.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m   2971\u001b[0m     copy\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mInlineData(values\u001b[38;5;241m=\u001b[39m[{}])  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   2972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Chart, copy)\u001b[38;5;241m.\u001b[39mto_dict(\n\u001b[1;32m   2973\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m, ignore\u001b[38;5;241m=\u001b[39mignore, context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m   2974\u001b[0m     )\n\u001b[0;32m-> 2975\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/vegalite/v5/api.py:950\u001b[0m, in \u001b[0;36mTopLevelMixin.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m    948\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    949\u001b[0m original_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(copy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, Undefined)\n\u001b[0;32m--> 950\u001b[0m copy\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined:\n\u001b[1;32m    953\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m original_data\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/vegalite/v5/api.py:111\u001b[0m, in \u001b[0;36m_prepare_data\u001b[0;34m(data, context)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# convert dataframes  or objects with __geo_interface__ to dict\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__geo_interface__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_transformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# convert string input to a URLData\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/toolz/functoolz.py:304\u001b[0m, in \u001b[0;36mcurry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_curry(args, kwargs, exc):\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/vegalite/data.py:23\u001b[0m, in \u001b[0;36mdefault_data_transformer\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@curried\u001b[39m\u001b[38;5;241m.\u001b[39mcurry\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_data_transformer\u001b[39m(\n\u001b[1;32m     21\u001b[0m     data: DataType, max_rows: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m     22\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ToValuesReturnType:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcurried\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/toolz/functoolz.py:304\u001b[0m, in \u001b[0;36mcurry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_curry(args, kwargs, exc):\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/utils/data.py:117\u001b[0m, in \u001b[0;36mlimit_rows\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa_table\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_rows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m>\u001b[39m max_rows:\n\u001b[0;32m--> 117\u001b[0m     \u001b[43mraise_max_rows_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/utils/data.py:81\u001b[0m, in \u001b[0;36mlimit_rows.<locals>.raise_max_rows_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_max_rows_error\u001b[39m():\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRowsError(\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of rows in your dataset is greater \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan the maximum allowed (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry enabling the VegaFusion data transformer which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraises this limit by pre-evaluating data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformations in Python.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    >> import altair as alt\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m    >> alt.data_transformers.enable(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvegafusion\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOr, see https://altair-viz.github.io/user_guide/large_datasets.html \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor additional information\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon how to plot large datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m     )\n",
      "\u001b[0;31mMaxRowsError\u001b[0m: The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets."
     ]
    }
   ],
   "source": [
    "from altair_saver import save\n",
    "\n",
    "# Save the chart as a PNG image\n",
    "save(chart1, 'chart1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRowsError",
     "evalue": "The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxRowsError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maltair_saver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save the chart as a PNG image\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchart1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchart1.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair_saver/_core.py:161\u001b[0m, in \u001b[0;36msave\u001b[0;34m(chart, fp, fmt, mode, embed_options, method, suppress_data_warning, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m alt\u001b[38;5;241m.\u001b[39mdata_transformers\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;129;01min\u001b[39;00m [alt\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto_json, alt\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto_csv]:\n\u001b[1;32m    156\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave() may not function properly with the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malt\u001b[38;5;241m.\u001b[39mdata_transformers\u001b[38;5;241m.\u001b[39mactive\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata transformer: use alt.data_transformers.enable(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m). To \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuppress this warning, pass suppress_data_warning=True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mchart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     mode \u001b[38;5;241m=\u001b[39m infer_mode_from_spec(spec)\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/vegalite/v5/api.py:2975\u001b[0m, in \u001b[0;36mChart.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m   2971\u001b[0m     copy\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mInlineData(values\u001b[38;5;241m=\u001b[39m[{}])  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   2972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Chart, copy)\u001b[38;5;241m.\u001b[39mto_dict(\n\u001b[1;32m   2973\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m, ignore\u001b[38;5;241m=\u001b[39mignore, context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[1;32m   2974\u001b[0m     )\n\u001b[0;32m-> 2975\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/vegalite/v5/api.py:950\u001b[0m, in \u001b[0;36mTopLevelMixin.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m    948\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    949\u001b[0m original_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(copy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, Undefined)\n\u001b[0;32m--> 950\u001b[0m copy\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined:\n\u001b[1;32m    953\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m original_data\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/vegalite/v5/api.py:111\u001b[0m, in \u001b[0;36m_prepare_data\u001b[0;34m(data, context)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# convert dataframes  or objects with __geo_interface__ to dict\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__geo_interface__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_transformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# convert string input to a URLData\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/toolz/functoolz.py:304\u001b[0m, in \u001b[0;36mcurry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_curry(args, kwargs, exc):\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/vegalite/data.py:23\u001b[0m, in \u001b[0;36mdefault_data_transformer\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@curried\u001b[39m\u001b[38;5;241m.\u001b[39mcurry\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_data_transformer\u001b[39m(\n\u001b[1;32m     21\u001b[0m     data: DataType, max_rows: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m     22\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ToValuesReturnType:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcurried\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/toolz/functoolz.py:304\u001b[0m, in \u001b[0;36mcurry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_curry(args, kwargs, exc):\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/utils/data.py:117\u001b[0m, in \u001b[0;36mlimit_rows\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa_table\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_rows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m>\u001b[39m max_rows:\n\u001b[0;32m--> 117\u001b[0m     \u001b[43mraise_max_rows_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/altair/utils/data.py:81\u001b[0m, in \u001b[0;36mlimit_rows.<locals>.raise_max_rows_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_max_rows_error\u001b[39m():\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRowsError(\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of rows in your dataset is greater \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan the maximum allowed (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry enabling the VegaFusion data transformer which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraises this limit by pre-evaluating data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformations in Python.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    >> import altair as alt\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m    >> alt.data_transformers.enable(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvegafusion\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOr, see https://altair-viz.github.io/user_guide/large_datasets.html \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor additional information\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon how to plot large datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m     )\n",
      "\u001b[0;31mMaxRowsError\u001b[0m: The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets."
     ]
    }
   ],
   "source": [
    "from altair_saver import save\n",
    "\n",
    "# Save the chart as a PNG image\n",
    "save(chart1, 'chart1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'chart1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Display the saved image\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchart1.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/IPython/core/display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/IPython/core/display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/IPython/core/display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[1;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/IPython/core/display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chart1.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display the saved image\n",
    "Image(filename='chart1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get public holidays and weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Trip Start Time' to date only (no time component)\n",
    "df['Trip Start Date'] = pd.to_datetime(df['Trip Start Time']).dt.date\n",
    "\n",
    "# Get public holidays for Nigeria (replace with appropriate API/data source if needed)\n",
    "def get_public_holidays(year):\n",
    "    url = f\"https://date.nager.at/api/v3/PublicHolidays/{year}/NG\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return [datetime.strptime(holiday['date'], '%Y-%m-%d').date() for holiday in response.json()]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "holidays_2021 = get_public_holidays(2021)\n",
    "\n",
    "df['is_holiday'] = df['Trip Start Date'].isin(holidays_2021).astype(int)\n",
    "\n",
    "# 2. Weekend vs. Weekday\n",
    "df['is_weekend'] = pd.to_datetime(df['Trip Start Time']).dt.dayofweek.isin([5, 6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv\n",
    "df.to_csv('../data/completed_orders_with_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Trip ID   | Trip Origin                        | Trip Destination                | Trip Start Time   | Trip End Time       | day_of_week   | hour_of_day   | day_of_month   | month   | Trip Origin_latitude   | Trip Origin_longitude   | Trip Destination_latitude   | Trip Destination_longitude   | trip_duration   | is_holiday   | is_weekend   | Trip Start Date   |\n",
      "|:----------|:-----------------------------------|:--------------------------------|:------------------|:--------------------|:--------------|:--------------|:---------------|:--------|:-----------------------|:------------------------|:----------------------------|:-----------------------------|:----------------|:-------------|:-------------|:------------------|\n",
      "| 391996    | 6.508813001668548,3.37740316890347 | 6.650969799999999,3.3450307     | 2021-07-01        | 2021-07-01 07:29:37 | Thursday      | 7             | 1              | July    | 6.50881                | 3.3774                  | 6.65097                     | 3.34503                      | 93              | 0            | 0            | 2021-07-01        |\n",
      "| 391997    | 6.4316714,3.4555375                | 6.4280814653326,3.4721885847586 | 2021-07-01        | 2021-07-01 07:07:28 | Thursday      | 6             | 1              | July    | 6.43167                | 3.45554                 | 6.42808                     | 3.47219                      | 1764            | 0            | 0            | 2021-07-01        |\n",
      "| 391998    | 6.631679399999999,3.3388976        | 6.508324099999999,3.3590397     | 2021-07-01        | 2021-07-01 07:02:23 | Thursday      | 6             | 1              | July    | 6.63168                | 3.3389                  | 6.50832                     | 3.35904                      | 2481            | 0            | 0            | 2021-07-01        |\n",
      "| 391999    | 6.572757200000001,3.3677082        | 6.584881099999999,3.3614073     | 2021-07-01        | 2021-07-01 07:29:42 | Thursday      | 7             | 1              | July    | 6.57276                | 3.36771                 | 6.58488                     | 3.36141                      | 815             | 0            | 0            | 2021-07-01        |\n",
      "| 392001    | 6.6010417,3.2766339                | 6.4501069,3.3916154             | 2021-07-01        | 2021-07-01 09:34:36 | Thursday      | 9             | 1              | July    | 6.60104                | 3.27663                 | 6.45011                     | 3.39162                      | 217             | 0            | 0            | 2021-07-01        |\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_orders = pd.read_csv('../data/completed_orders_with_features.csv')\n",
    "drivers_location = pd.read_csv('../data/drivers_location_during_request.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"6a3c58c45a46fa944097a6ca00cb8f8d\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# 1. Rename `Trip ID` to `order_id` in completed_orders\n",
    "completed_orders = completed_orders.rename(columns={'Trip ID': 'order_id'})\n",
    "\n",
    "# 2. Convert `order_id` to string in both DataFrames\n",
    "completed_orders['order_id'] = completed_orders['order_id'].astype(str)\n",
    "drivers_location['order_id'] = drivers_location['order_id'].astype(str)\n",
    "\n",
    "# 3. Merge the DataFrames on `order_id` using a left join\n",
    "merged_df = completed_orders.merge(drivers_location, on='order_id', how='left')\n",
    "\n",
    "# 4. Convert the `Trip Start Time` and `Trip End Time` columns to datetime in `merged_df`\n",
    "merged_df['Trip Start Time'] = pd.to_datetime(merged_df['Trip Start Time'])\n",
    "merged_df['Trip End Time'] = pd.to_datetime(merged_df['Trip End Time'])\n",
    "\n",
    "# 5. Drop the updated_at and created_at columns\n",
    "merged_df = merged_df.drop(columns=['updated_at', 'created_at'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>Trip Origin</th>\n",
       "      <th>Trip Destination</th>\n",
       "      <th>Trip Start Time</th>\n",
       "      <th>Trip End Time</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "      <th>Trip Origin_latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>Trip Start Date</th>\n",
       "      <th>id</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>driver_action</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391996</td>\n",
       "      <td>6.508813001668548,3.37740316890347</td>\n",
       "      <td>6.650969799999999,3.3450307</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 07:29:37</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.508813</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>391997</td>\n",
       "      <td>6.4316714,3.4555375</td>\n",
       "      <td>6.4280814653326,3.4721885847586</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 07:07:28</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.431671</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>391998</td>\n",
       "      <td>6.631679399999999,3.3388976</td>\n",
       "      <td>6.508324099999999,3.3590397</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 07:02:23</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.631679</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>391999</td>\n",
       "      <td>6.572757200000001,3.3677082</td>\n",
       "      <td>6.584881099999999,3.3614073</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 07:29:42</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.572757</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392001</td>\n",
       "      <td>6.6010417,3.2766339</td>\n",
       "      <td>6.4501069,3.3916154</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>243828.0</td>\n",
       "      <td>accepted</td>\n",
       "      <td>6.602207</td>\n",
       "      <td>3.270465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>392001</td>\n",
       "      <td>6.6010417,3.2766339</td>\n",
       "      <td>6.4501069,3.3916154</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>243588.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>6.592097</td>\n",
       "      <td>3.287445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>392001</td>\n",
       "      <td>6.6010417,3.2766339</td>\n",
       "      <td>6.4501069,3.3916154</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>243830.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>6.596133</td>\n",
       "      <td>3.281784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>392001</td>\n",
       "      <td>6.6010417,3.2766339</td>\n",
       "      <td>6.4501069,3.3916154</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>243539.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>6.596142</td>\n",
       "      <td>3.280526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>392001</td>\n",
       "      <td>6.6010417,3.2766339</td>\n",
       "      <td>6.4501069,3.3916154</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>171653.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>6.609232</td>\n",
       "      <td>3.288800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>392001</td>\n",
       "      <td>6.6010417,3.2766339</td>\n",
       "      <td>6.4501069,3.3916154</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>245662.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>6.593095</td>\n",
       "      <td>3.287759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_id                         Trip Origin  \\\n",
       "0   391996  6.508813001668548,3.37740316890347   \n",
       "1   391997                 6.4316714,3.4555375   \n",
       "2   391998         6.631679399999999,3.3388976   \n",
       "3   391999         6.572757200000001,3.3677082   \n",
       "4   392001                 6.6010417,3.2766339   \n",
       "5   392001                 6.6010417,3.2766339   \n",
       "6   392001                 6.6010417,3.2766339   \n",
       "7   392001                 6.6010417,3.2766339   \n",
       "8   392001                 6.6010417,3.2766339   \n",
       "9   392001                 6.6010417,3.2766339   \n",
       "\n",
       "                  Trip Destination Trip Start Time       Trip End Time  \\\n",
       "0      6.650969799999999,3.3450307      2021-07-01 2021-07-01 07:29:37   \n",
       "1  6.4280814653326,3.4721885847586      2021-07-01 2021-07-01 07:07:28   \n",
       "2      6.508324099999999,3.3590397      2021-07-01 2021-07-01 07:02:23   \n",
       "3      6.584881099999999,3.3614073      2021-07-01 2021-07-01 07:29:42   \n",
       "4              6.4501069,3.3916154      2021-07-01 2021-07-01 09:34:36   \n",
       "5              6.4501069,3.3916154      2021-07-01 2021-07-01 09:34:36   \n",
       "6              6.4501069,3.3916154      2021-07-01 2021-07-01 09:34:36   \n",
       "7              6.4501069,3.3916154      2021-07-01 2021-07-01 09:34:36   \n",
       "8              6.4501069,3.3916154      2021-07-01 2021-07-01 09:34:36   \n",
       "9              6.4501069,3.3916154      2021-07-01 2021-07-01 09:34:36   \n",
       "\n",
       "  day_of_week  hour_of_day  day_of_month month  Trip Origin_latitude  ...  \\\n",
       "0    Thursday            7             1  July              6.508813  ...   \n",
       "1    Thursday            6             1  July              6.431671  ...   \n",
       "2    Thursday            6             1  July              6.631679  ...   \n",
       "3    Thursday            7             1  July              6.572757  ...   \n",
       "4    Thursday            9             1  July              6.601042  ...   \n",
       "5    Thursday            9             1  July              6.601042  ...   \n",
       "6    Thursday            9             1  July              6.601042  ...   \n",
       "7    Thursday            9             1  July              6.601042  ...   \n",
       "8    Thursday            9             1  July              6.601042  ...   \n",
       "9    Thursday            9             1  July              6.601042  ...   \n",
       "\n",
       "   is_holiday  is_weekend  Trip Start Date   id  driver_id  driver_action  \\\n",
       "0           0           0       2021-07-01  NaN        NaN            NaN   \n",
       "1           0           0       2021-07-01  NaN        NaN            NaN   \n",
       "2           0           0       2021-07-01  NaN        NaN            NaN   \n",
       "3           0           0       2021-07-01  NaN        NaN            NaN   \n",
       "4           0           0       2021-07-01  1.0   243828.0       accepted   \n",
       "5           0           0       2021-07-01  2.0   243588.0       rejected   \n",
       "6           0           0       2021-07-01  3.0   243830.0       rejected   \n",
       "7           0           0       2021-07-01  4.0   243539.0       rejected   \n",
       "8           0           0       2021-07-01  5.0   171653.0       rejected   \n",
       "9           0           0       2021-07-01  6.0   245662.0       rejected   \n",
       "\n",
       "        lat       lng  created_at updated_at  \n",
       "0       NaN       NaN         NaN        NaN  \n",
       "1       NaN       NaN         NaN        NaN  \n",
       "2       NaN       NaN         NaN        NaN  \n",
       "3       NaN       NaN         NaN        NaN  \n",
       "4  6.602207  3.270465         NaN        NaN  \n",
       "5  6.592097  3.287445         NaN        NaN  \n",
       "6  6.596133  3.281784         NaN        NaN  \n",
       "7  6.596142  3.280526         NaN        NaN  \n",
       "8  6.609232  3.288800         NaN        NaN  \n",
       "9  6.593095  3.287759         NaN        NaN  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x75bb2a7a65e0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hilla/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Extract `latitude` and `longitude` from `Trip Origin` and `Trip Destination` in `merged_df`\n",
    "for col in ['Trip Origin', 'Trip Destination']:\n",
    "    merged_df[[f'{col}_latitude', f'{col}_longitude']] = merged_df[col].str.split(',', expand=True).astype(float)\n",
    "\n",
    "# 6. Filter to keep only rows where `driver_action` is 'accepted' and create a copy\n",
    "merged_df_accepted_copy = merged_df[merged_df['driver_action'] == 'accepted'].copy()\n",
    "\n",
    "# 7. Define a function `get_weather` that takes latitude, longitude, and API key as input and returns the weather description from the OpenWeatherMap API.\n",
    "def get_weather(lat, lon, api_key):\n",
    "    base_url = \"https://api.openweathermap.org/data/3.0/onecall?\"\n",
    "    complete_url = base_url + \"lat=\" + str(lat) + \"&lon=\" + str(lon) + \"&appid=\" + api_key\n",
    "    response = requests.get(complete_url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        weather_description = data['current']['weather'][0]['description']\n",
    "        return weather_description\n",
    "    else:\n",
    "        print(\"Error in API call\")\n",
    "        return None\n",
    "\n",
    "# 8. Apply the `get_weather` function to the `merged_df_accepted_copy` DataFrame to get the weather conditions for each driver's location.\n",
    "merged_df_accepted_copy['weather_description'] = merged_df_accepted_copy.apply(\n",
    "    lambda row: get_weather(row['lat'], row['lng'], api_key), axis=1\n",
    ")\n",
    "\n",
    "# 9. Display the first 5 rows of the dataframe with the weather description.\n",
    "print(merged_df_accepted_copy[['order_id', 'weather_description']].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>Trip Origin</th>\n",
       "      <th>Trip Destination</th>\n",
       "      <th>Trip Start Time</th>\n",
       "      <th>Trip End Time</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "      <th>Trip Origin_latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>Trip Start Date</th>\n",
       "      <th>id</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>driver_action</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392001</td>\n",
       "      <td>6.6010417,3.2766339</td>\n",
       "      <td>6.4501069,3.3916154</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>243828.0</td>\n",
       "      <td>accepted</td>\n",
       "      <td>6.602207</td>\n",
       "      <td>3.270465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>392005</td>\n",
       "      <td>6.565087699999999,3.3844415</td>\n",
       "      <td>6.499696300000001,3.3509075</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 11:27:51</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.565088</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>11.0</td>\n",
       "      <td>245597.0</td>\n",
       "      <td>accepted</td>\n",
       "      <td>6.549147</td>\n",
       "      <td>3.392184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>392009</td>\n",
       "      <td>6.6636484,3.3082058</td>\n",
       "      <td>6.6185421,3.301634</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 07:41:12</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.663648</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>62.0</td>\n",
       "      <td>245600.0</td>\n",
       "      <td>accepted</td>\n",
       "      <td>6.644829</td>\n",
       "      <td>3.289328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>392013</td>\n",
       "      <td>6.4308171,3.4341552</td>\n",
       "      <td>6.435460000000001,3.4846547</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 09:19:11</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.430817</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>129.0</td>\n",
       "      <td>243892.0</td>\n",
       "      <td>accepted</td>\n",
       "      <td>6.435331</td>\n",
       "      <td>3.424317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>392014</td>\n",
       "      <td>6.499156300000001,3.3585173</td>\n",
       "      <td>6.4280911,3.5157172</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>2021-07-01 07:27:24</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>6.499156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>142.0</td>\n",
       "      <td>243781.0</td>\n",
       "      <td>accepted</td>\n",
       "      <td>6.498221</td>\n",
       "      <td>3.360042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id                  Trip Origin             Trip Destination  \\\n",
       "4     392001          6.6010417,3.2766339          6.4501069,3.3916154   \n",
       "14    392005  6.565087699999999,3.3844415  6.499696300000001,3.3509075   \n",
       "65    392009          6.6636484,3.3082058           6.6185421,3.301634   \n",
       "132   392013          6.4308171,3.4341552  6.435460000000001,3.4846547   \n",
       "145   392014  6.499156300000001,3.3585173          6.4280911,3.5157172   \n",
       "\n",
       "    Trip Start Time       Trip End Time day_of_week  hour_of_day  \\\n",
       "4        2021-07-01 2021-07-01 09:34:36    Thursday            9   \n",
       "14       2021-07-01 2021-07-01 11:27:51    Thursday           10   \n",
       "65       2021-07-01 2021-07-01 07:41:12    Thursday            6   \n",
       "132      2021-07-01 2021-07-01 09:19:11    Thursday            8   \n",
       "145      2021-07-01 2021-07-01 07:27:24    Thursday            6   \n",
       "\n",
       "     day_of_month month  Trip Origin_latitude  ...  is_holiday  is_weekend  \\\n",
       "4               1  July              6.601042  ...           0           0   \n",
       "14              1  July              6.565088  ...           0           0   \n",
       "65              1  July              6.663648  ...           0           0   \n",
       "132             1  July              6.430817  ...           0           0   \n",
       "145             1  July              6.499156  ...           0           0   \n",
       "\n",
       "     Trip Start Date     id  driver_id  driver_action       lat       lng  \\\n",
       "4         2021-07-01    1.0   243828.0       accepted  6.602207  3.270465   \n",
       "14        2021-07-01   11.0   245597.0       accepted  6.549147  3.392184   \n",
       "65        2021-07-01   62.0   245600.0       accepted  6.644829  3.289328   \n",
       "132       2021-07-01  129.0   243892.0       accepted  6.435331  3.424317   \n",
       "145       2021-07-01  142.0   243781.0       accepted  6.498221  3.360042   \n",
       "\n",
       "     created_at updated_at  \n",
       "4           NaN        NaN  \n",
       "14          NaN        NaN  \n",
       "65          NaN        NaN  \n",
       "132         NaN        NaN  \n",
       "145         NaN        NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_accepted_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/features/merged_df_accepted_copy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call to request historical data:\n",
    "\n",
    "lat, lon = (6.6010417,3.2766339)\n",
    "time = 1627830000\n",
    "api_key = os.getenv(\"OPENWEATHERMAP_API_KEY\")\n",
    "\n",
    "response = requests.get(\n",
    "            f\"https://api.openweathermap.org/data/3.0/onecall/timemachine?lat={lat}&lon={lon}&dt={time}&appid={api_key}\"\n",
    "          )\n",
    "\n",
    "def get_weather(timestamp, lat, lon):\n",
    "    base_url = \"http://api.openweathermap.org/data/2.0/onecall?\"\n",
    "    complete_url = base_url + \"lat=\" + str(lat) + \"&lon=\" + str(lon) + \"&appid=\" + api_key\n",
    "    response = requests.get(complete_url) \n",
    "    x = response.json()\n",
    "    if x[\"cod\"] != \"404\":\n",
    "        return x['weather'][0]['main']  # Simplify to just the main weather condition\n",
    "    else:\n",
    "        return np.nan  # Missing if API call fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': 6.601,\n",
       " 'lon': 3.2766,\n",
       " 'timezone': 'Africa/Lagos',\n",
       " 'timezone_offset': 3600,\n",
       " 'data': [{'dt': 1627830000,\n",
       "   'sunrise': 1627796462,\n",
       "   'sunset': 1627841116,\n",
       "   'temp': 301.54,\n",
       "   'feels_like': 303.45,\n",
       "   'pressure': 1016,\n",
       "   'humidity': 62,\n",
       "   'dew_point': 293.56,\n",
       "   'clouds': 40,\n",
       "   'visibility': 10000,\n",
       "   'wind_speed': 5.14,\n",
       "   'wind_deg': 250,\n",
       "   'weather': [{'id': 802,\n",
       "     'main': 'Clouds',\n",
       "     'description': 'scattered clouds',\n",
       "     'icon': '03d'}]}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming you have your 'completed_orders' DataFrame loaded\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# (including 'Trip Start Time', 'Trip Origin_latitude', and 'Trip Origin_longitude')\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 1. Public Holiday Data (Example using a public API)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get public holidays for Nigeria (replace with appropriate API/data source if needed)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming you have your 'completed_orders' DataFrame loaded\n",
    "# (including 'Trip Start Time', 'Trip Origin_latitude', and 'Trip Origin_longitude')\n",
    "\n",
    "# 1. Public Holiday Data (Example using a public API)\n",
    "# Get public holidays for Nigeria (replace with appropriate API/data source if needed)\n",
    "def get_public_holidays(year):\n",
    "    url = f\"https://date.nager.at/api/v3/PublicHolidays/{year}/NG\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return [datetime.strptime(holiday['date'], '%Y-%m-%d') for holiday in response.json()]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "holidays_2021 = get_public_holidays(2021)  # Adjust years as needed for your data\n",
    "\n",
    "df['is_holiday'] = df['Trip Start Time'].dt.date.isin(holidays_2021).astype(int)\n",
    "\n",
    "# 2. Weekend vs. Weekday\n",
    "df['is_weekend'] = df['Trip Start Time'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "\n",
    "# 3. Hour of the Day (Already extracted in previous steps)\n",
    "\n",
    "# 4. Weather Data (Example using OpenWeatherMap API)\n",
    "# You'll need to get an API key from OpenWeatherMap\n",
    "api_key = \"YOUR_API_KEY\" \n",
    "\n",
    "def get_weather(timestamp, lat, lon):\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "    complete_url = base_url + \"lat=\" + str(lat) + \"&lon=\" + str(lon) + \"&appid=\" + api_key\n",
    "    response = requests.get(complete_url) \n",
    "    x = response.json()\n",
    "    if x[\"cod\"] != \"404\":\n",
    "        return x['weather'][0]['main']  # Simplify to just the main weather condition\n",
    "    else:\n",
    "        return np.nan  # Missing if API call fails\n",
    "\n",
    "# Apply the weather function to get weather conditions (This might take a while for a large dataset)\n",
    "df['weather_condition'] = df.apply(lambda row: get_weather(row['Trip Start Time'], row['Trip Origin_latitude'], row['Trip Origin_longitude']), axis=1)\n",
    "\n",
    "# 5. Traffic Data (Example using TomTom API or other traffic data sources)\n",
    "# You'll need to adapt this to your chosen API/data source.\n",
    "# This is a complex process and may require additional data processing based on your API's response.\n",
    "\n",
    "# 6. Special Occasions (This requires manual research or finding relevant datasets)\n",
    "# You'll need to identify special events in Lagos for your data's time period and create a feature.\n",
    "\n",
    "\n",
    "# 7. Relevance Analysis\n",
    "# Example: Use a logistic regression model to assess feature importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Choose features and target variable\n",
    "X = df[['is_holiday', 'is_weekend', 'hour_of_day', 'weather_condition']]  # Add more features as available\n",
    "y = df['trip_duration'] # Or another target variable representing order completion\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print feature importance\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': model.coef_[0]})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weather'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan  \u001b[38;5;66;03m# Missing if API call fails\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Apply the weather function to get weather conditions (This might take a while for a large dataset)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather_condition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_weather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrip Start Time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrip Origin_latitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrip Origin_longitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan  \u001b[38;5;66;03m# Missing if API call fails\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Apply the weather function to get weather conditions (This might take a while for a large dataset)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather_condition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mget_weather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrip Start Time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrip Origin_latitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrip Origin_longitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m, in \u001b[0;36mget_weather\u001b[0;34m(timestamp, lat, lon)\u001b[0m\n\u001b[1;32m      9\u001b[0m x \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcod\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m404\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweather\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Simplify to just the main weather condition\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weather'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Weather Data (Example using OpenWeatherMap API)\n",
    "# You'll need to get an API key from OpenWeatherMap\n",
    "api_key = \"6a3c58c45a46fa944097a6ca00cb8f8d\" \n",
    "\n",
    "def get_weather(timestamp, lat, lon):\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "    complete_url = base_url + \"lat=\" + str(lat) + \"&lon=\" + str(lon) + \"&appid=\" + api_key\n",
    "    response = requests.get(complete_url) \n",
    "    x = response.json()\n",
    "    if x[\"cod\"] != \"404\":\n",
    "        return x['weather'][0]['main']  # Simplify to just the main weather condition\n",
    "    else:\n",
    "        return np.nan  # Missing if API call fails\n",
    "\n",
    "# Apply the weather function to get weather conditions (This might take a while for a large dataset)\n",
    "df['weather_condition'] = df.apply(lambda row: get_weather(row['Trip Start Time'], row['Trip Origin_latitude'], row['Trip Origin_longitude']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ord() expected string of length 1, but list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# enrich your `completed_orders` DataFrame\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m enriched_df \u001b[38;5;241m=\u001b[39m \u001b[43menrich_completed_orders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(enriched_df\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;241m.\u001b[39mto_markdown(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, numalign\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, stralign\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[6], line 55\u001b[0m, in \u001b[0;36menrich_completed_orders\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     52\u001b[0m start_time \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrip Start Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     53\u001b[0m end_time \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrip End Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 55\u001b[0m route_info \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_route_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m route_info:\n\u001b[1;32m     57\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(route_info)\n",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m, in \u001b[0;36mcalculate_route_info\u001b[0;34m(start_coords, end_coords, start_time, end_time)\u001b[0m\n\u001b[1;32m     21\u001b[0m       total_duration \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# In seconds\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Corrected polyline decoding:\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m       decoded_polyline \u001b[38;5;241m=\u001b[39m \u001b[43mpolyline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoordinates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeojson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m       \u001b[38;5;66;03m# Calculate additional metrics\u001b[39;00m\n\u001b[1;32m     26\u001b[0m       straight_line_distance \u001b[38;5;241m=\u001b[39m geodesic(start_coords, end_coords)\u001b[38;5;241m.\u001b[39mmeters\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/polyline/polyline.py:60\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(expression, precision, geojson)\u001b[0m\n\u001b[1;32m     57\u001b[0m coordinates, index, lat, lng, length, factor \u001b[38;5;241m=\u001b[39m [], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(expression), \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m precision)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m index \u001b[38;5;241m<\u001b[39m length:\n\u001b[0;32m---> 60\u001b[0m     lat_change, index \u001b[38;5;241m=\u001b[39m \u001b[43m_trans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     lng_change, index \u001b[38;5;241m=\u001b[39m _trans(expression, index)\n\u001b[1;32m     62\u001b[0m     lat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lat_change\n",
      "File \u001b[0;32m~/code/10Academy-training/week8/Causal-Inference-Delivery-Logistic-Location-Optimization/.venv/lib/python3.9/site-packages/polyline/polyline.py:38\u001b[0m, in \u001b[0;36m_trans\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m     36\u001b[0m comp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m byte \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m byte \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x20\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m     byte \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m63\u001b[39m\n\u001b[1;32m     39\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     40\u001b[0m     result \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m (byte \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0x1f\u001b[39m) \u001b[38;5;241m<<\u001b[39m shift\n",
      "\u001b[0;31mTypeError\u001b[0m: ord() expected string of length 1, but list found"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import polyline\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual OpenRouteService API key\n",
    "ORS_API_KEY = '5b3ce3597851110001cf624897f57a95cf064c12bc59c0d460fdf85f'\n",
    "\n",
    "def calculate_route_info(start_coords, end_coords, start_time, end_time):\n",
    "    \"\"\"Calculates route information using OpenRouteService API.\"\"\"\n",
    "\n",
    "    url = f\"https://api.openrouteservice.org/v2/directions/driving-car?api_key={ORS_API_KEY}&start={start_coords[1]},{start_coords[0]}&end={end_coords[1]},{end_coords[0]}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract key information from the API response\n",
    "        total_distance = data['features'][0]['properties']['summary']['distance']\n",
    "        total_duration = data['features'][0]['properties']['summary']['duration']  # In seconds\n",
    "  # Corrected polyline decoding:\n",
    "        decoded_polyline = polyline.decode(data['features'][0]['geometry']['coordinates'], geojson=True)\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        straight_line_distance = geodesic(start_coords, end_coords).meters\n",
    "        average_speed = (total_distance / total_duration) * 3.6  # Convert m/s to km/h\n",
    "        trip_duration = end_time - start_time  # Assuming datetime objects\n",
    "\n",
    "        return {\n",
    "            'start_coords': start_coords,\n",
    "            'end_coords': end_coords,\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'total_distance': total_distance,\n",
    "            'total_duration': total_duration,\n",
    "            'straight_line_distance': straight_line_distance,\n",
    "            'average_speed': average_speed,\n",
    "            'trip_duration': trip_duration.total_seconds(),\n",
    "            'route_coordinates': decoded_polyline\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage with the 'completed_orders' DataFrame\n",
    "def enrich_completed_orders(df):\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        start_coords = (row['Trip Origin_latitude'], row['Trip Origin_longitude'])\n",
    "        end_coords = (row['Trip Destination_latitude'], row['Trip Destination_longitude'])\n",
    "        start_time = row['Trip Start Time']\n",
    "        end_time = row['Trip End Time']\n",
    "        \n",
    "        route_info = calculate_route_info(start_coords, end_coords, start_time, end_time)\n",
    "        if route_info:\n",
    "            results.append(route_info)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# enrich your `completed_orders` DataFrame\n",
    "enriched_df = enrich_completed_orders(df)\n",
    "print(enriched_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
